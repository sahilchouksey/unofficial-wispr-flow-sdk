<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Wispr Flow SDK - Microphone</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: #0a0a0a;
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      color: #fff;
      padding: 20px;
    }

    .container {
      text-align: center;
      max-width: 480px;
      width: 100%;
    }

    h1 {
      font-size: 1.5rem;
      font-weight: 500;
      margin-bottom: 0.25rem;
      color: #fff;
    }

    .subtitle {
      color: #666;
      font-size: 0.85rem;
      margin-bottom: 2.5rem;
    }

    .voice-btn {
      width: 100px;
      height: 100px;
      border-radius: 50%;
      border: 2px solid #333;
      background: transparent;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.15s ease;
      margin: 0 auto;
    }

    .voice-btn:hover {
      border-color: #555;
      background: #111;
    }

    .voice-btn.recording {
      border-color: #fff;
      background: #fff;
    }

    .voice-btn svg {
      width: 32px;
      height: 32px;
      fill: #fff;
      transition: all 0.15s ease;
    }

    .voice-btn.recording svg {
      fill: #0a0a0a;
    }

    .visualizer {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 3px;
      height: 32px;
      margin: 1.5rem 0;
      opacity: 0;
      transition: opacity 0.15s;
    }

    .visualizer.visible { opacity: 1; }

    .visualizer-bar {
      width: 3px;
      background: #fff;
      border-radius: 2px;
      transition: height 0.05s ease;
    }

    .status {
      font-size: 0.9rem;
      color: #666;
      min-height: 20px;
    }

    .status.recording { color: #fff; }
    .status.processing { color: #888; }

    .timer {
      font-size: 1.25rem;
      font-weight: 500;
      font-family: 'SF Mono', Monaco, monospace;
      color: #fff;
      margin-top: 0.5rem;
      opacity: 0;
      transition: opacity 0.15s;
    }

    .timer.visible { opacity: 1; }

    .transcripts {
      margin-top: 2.5rem;
      text-align: left;
    }

    .transcripts h2 {
      font-size: 0.75rem;
      font-weight: 500;
      color: #555;
      text-transform: uppercase;
      letter-spacing: 0.5px;
      margin-bottom: 1rem;
    }

    .transcript-item {
      background: #111;
      border-radius: 8px;
      padding: 1rem;
      margin-bottom: 0.5rem;
      border-left: 2px solid #333;
      animation: fadeIn 0.2s ease;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(8px); }
      to { opacity: 1; transform: translateY(0); }
    }

    .transcript-item .text {
      font-size: 1rem;
      line-height: 1.5;
      color: #fff;
    }

    .transcript-item .meta {
      font-size: 0.7rem;
      color: #555;
      margin-top: 0.5rem;
      display: flex;
      gap: 1rem;
    }

    .empty-state {
      color: #444;
      font-size: 0.9rem;
      padding: 1.5rem;
      text-align: center;
    }

    .error {
      background: #1a0a0a;
      border: 1px solid #333;
      border-radius: 8px;
      padding: 1rem;
      margin-top: 1rem;
      color: #ff6b6b;
      font-size: 0.85rem;
    }

    .hint {
      margin-top: 2rem;
      font-size: 0.75rem;
      color: #444;
    }

    .hint kbd {
      background: #1a1a1a;
      padding: 2px 6px;
      border-radius: 4px;
      border: 1px solid #333;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Wispr Flow SDK</h1>
    <p class="subtitle">Voice to Text</p>

    <button class="voice-btn" id="voiceBtn">
      <svg id="micIcon" viewBox="0 0 24 24">
        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
        <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
      </svg>
      <svg id="stopIcon" viewBox="0 0 24 24" style="display:none">
        <rect x="6" y="6" width="12" height="12" rx="1"/>
      </svg>
    </button>

    <div class="visualizer" id="visualizer"></div>

    <p class="status" id="status">Click to record</p>
    <p class="timer" id="timer">00:00</p>

    <div class="transcripts">
      <h2>Transcripts</h2>
      <div id="transcriptsList">
        <p class="empty-state">Transcriptions appear here</p>
      </div>
    </div>

    <p class="hint">Press <kbd>Space</kbd> to toggle recording</p>
  </div>

  <script>
    const voiceBtn = document.getElementById('voiceBtn');
    const micIcon = document.getElementById('micIcon');
    const stopIcon = document.getElementById('stopIcon');
    const statusEl = document.getElementById('status');
    const timerEl = document.getElementById('timer');
    const visualizer = document.getElementById('visualizer');
    const transcriptsList = document.getElementById('transcriptsList');

    let isRecording = false;
    let mediaRecorder = null;
    let audioChunks = [];
    let recordingStartTime = null;
    let timerInterval = null;
    let audioContext = null;
    let analyser = null;
    let animationId = null;

    // Init visualizer
    for (let i = 0; i < 16; i++) {
      const bar = document.createElement('div');
      bar.className = 'visualizer-bar';
      bar.style.height = '4px';
      visualizer.appendChild(bar);
    }

    function updateVisualizer() {
      if (!analyser || !isRecording) return;
      const data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);
      const bars = visualizer.querySelectorAll('.visualizer-bar');
      const step = Math.floor(data.length / bars.length);
      bars.forEach((bar, i) => {
        const h = Math.max(4, (data[i * step] / 255) * 32);
        bar.style.height = h + 'px';
      });
      animationId = requestAnimationFrame(updateVisualizer);
    }

    function formatTime(s) {
      const m = Math.floor(s / 60);
      const sec = Math.floor(s % 60);
      return `${String(m).padStart(2,'0')}:${String(sec).padStart(2,'0')}`;
    }

    function updateTimer() {
      if (!recordingStartTime) return;
      timerEl.textContent = formatTime((Date.now() - recordingStartTime) / 1000);
    }

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        audioContext = new AudioContext();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 128;
        audioContext.createMediaStreamSource(stream).connect(analyser);

        const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
          ? 'audio/webm;codecs=opus' : 'audio/webm';
        mediaRecorder = new MediaRecorder(stream, { mimeType });
        audioChunks = [];

        mediaRecorder.ondataavailable = e => e.data.size > 0 && audioChunks.push(e.data);
        mediaRecorder.onstop = async () => {
          const blob = new Blob(audioChunks, { type: mimeType });
          const duration = (Date.now() - recordingStartTime) / 1000;
          stream.getTracks().forEach(t => t.stop());
          await transcribe(blob, duration);
        };

        mediaRecorder.start(100);
        recordingStartTime = Date.now();
        isRecording = true;

        voiceBtn.classList.add('recording');
        micIcon.style.display = 'none';
        stopIcon.style.display = 'block';
        statusEl.textContent = 'Recording...';
        statusEl.className = 'status recording';
        timerEl.classList.add('visible');
        visualizer.classList.add('visible');

        timerInterval = setInterval(updateTimer, 100);
        updateVisualizer();
      } catch (e) {
        showError('Microphone access denied');
      }
    }

    function stopRecording() {
      if (!mediaRecorder || !isRecording) return;
      mediaRecorder.stop();
      isRecording = false;

      voiceBtn.classList.remove('recording');
      micIcon.style.display = 'block';
      stopIcon.style.display = 'none';
      statusEl.textContent = 'Processing...';
      statusEl.className = 'status processing';
      visualizer.classList.remove('visible');

      clearInterval(timerInterval);
      cancelAnimationFrame(animationId);
      visualizer.querySelectorAll('.visualizer-bar').forEach(b => b.style.height = '4px');

      if (audioContext) {
        audioContext.close();
        audioContext = null;
        analyser = null;
      }
    }

    async function transcribe(blob, duration) {
      try {
        const form = new FormData();
        form.append('audio', blob, 'recording.webm');

        const res = await fetch('/transcribe', { method: 'POST', body: form });
        const data = await res.json();

        if (data.success) {
          addTranscript(data, duration);
        } else {
          showError(data.error || 'Transcription failed');
        }
      } catch (e) {
        showError('Transcription failed');
      }

      statusEl.textContent = 'Click to record';
      statusEl.className = 'status';
      timerEl.classList.remove('visible');
      timerEl.textContent = '00:00';
    }

    function addTranscript(data, duration) {
      const empty = transcriptsList.querySelector('.empty-state');
      if (empty) empty.remove();

      const text = data.text || '(No speech detected)';
      const lang = data.stats?.language || '-';
      const time = data.stats?.totalTime ? (data.stats.totalTime * 1000).toFixed(0) + 'ms' : '-';

      const item = document.createElement('div');
      item.className = 'transcript-item';
      item.innerHTML = `
        <div class="text">${text.replace(/</g,'&lt;')}</div>
        <div class="meta">
          <span>${duration.toFixed(1)}s</span>
          <span>${lang}</span>
          <span>${time}</span>
        </div>
      `;
      transcriptsList.insertBefore(item, transcriptsList.firstChild);
    }

    function showError(msg) {
      document.querySelector('.error')?.remove();
      const el = document.createElement('div');
      el.className = 'error';
      el.textContent = msg;
      document.querySelector('.container').appendChild(el);
      setTimeout(() => el.remove(), 4000);
    }

    voiceBtn.onclick = () => isRecording ? stopRecording() : startRecording();

    document.onkeydown = e => {
      if (e.code === 'Space' && e.target === document.body) {
        e.preventDefault();
        isRecording ? stopRecording() : startRecording();
      }
    };
  </script>
</body>
</html>
